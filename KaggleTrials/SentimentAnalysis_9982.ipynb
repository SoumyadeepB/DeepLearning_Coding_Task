{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/emotionrecognition/dev.json\n",
      "/kaggle/input/emotionrecognition/train.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.layers import Dense, Input, Flatten, Conv2D,Conv1D, MaxPooling2D,MaxPooling1D,GlobalMaxPooling1D\n",
    "from keras.layers import Reshape, Dropout, Concatenate, LSTM,Bidirectional,BatchNormalization\n",
    "from keras.layers import Flatten,Activation\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "import os\n",
    "import json\n",
    "from IPython.core.display import display, HTML\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "dir = '/kaggle/input/emotionrecognition/'\n",
    "PAD_ROWS=1800 \n",
    "PAD_COLS=26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(os.path.join(dir, 'train.json'), encoding=\"utf8\")\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valence</th>\n",
       "      <th>activation</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[5.502810676891276, 5.389630715979907, 5.8907...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[5.059076172970736, 5.288492317702101, 4.2633...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[4.218546271669202, 4.961436495859291, 3.6650...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[[4.650364321573866, 4.523905028353254, 5.0168...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[3.900221957277269, 2.7325726489808124, 2.565...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  valence activation                                           features\n",
       "0       0          1  [[5.502810676891276, 5.389630715979907, 5.8907...\n",
       "1       1          1  [[5.059076172970736, 5.288492317702101, 4.2633...\n",
       "2       0          1  [[4.218546271669202, 4.961436495859291, 3.6650...\n",
       "3       1          0  [[4.650364321573866, 4.523905028353254, 5.0168...\n",
       "4       0          1  [[3.900221957277269, 2.7325726489808124, 2.565..."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df= df.T\n",
    "TOTAL_DATA=df.shape[0]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7800"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf15443b4094d4788069bb37679f9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7800), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "feat = np.zeros((TOTAL_DATA,PAD_ROWS,PAD_COLS),dtype=np.float32)\n",
    "\n",
    "feature_set=pd.DataFrame(np.zeros((TOTAL_DATA,2),dtype=np.float32),columns=['features','label'])\n",
    "feature_set['features']=df['features']\n",
    "code=0\n",
    "for i in tqdm_notebook(range(TOTAL_DATA)):\n",
    "    \n",
    "    [r,c]=np.array(df['features'][i]).shape\n",
    "    feat[i,:r,:c]=np.array(normalize(df['features'][i]))\n",
    "    feature_set['features'][i]=feat[i]\n",
    "    v=df['valence'][i]\n",
    "    a=df['activation'][i]\n",
    "    \n",
    "    if v==0 and a==0:\n",
    "        code=0\n",
    "    elif v==0 and a==1:\n",
    "        code=1\n",
    "    elif v==1 and a==0:\n",
    "        code=2\n",
    "    elif v==1 and a==1:\n",
    "        code=3\n",
    "    feature_set['label'][i]=code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7800, 1800, 26)\n"
     ]
    }
   ],
   "source": [
    "print(feat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Create Separate Labelset for **Valence** and **Activation** </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 0 0 1]\n",
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels=feature_set['label'].astype(int)\n",
    "labels = pd.get_dummies(feature_set['label']).values.tolist()\n",
    "valence=np.array(df['valence'])\n",
    "activation=np.array(df['activation'])\n",
    "print(valence)\n",
    "print(activation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feat\n",
    "Y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, val_train, val_test = train_test_split(X, valence, test_size=0.10, random_state=96)\n",
    "# X_train, X_test, act_train, act_test = train_test_split(X, activation, test_size=0.10, random_state=96)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.10, random_state=96)\n",
    "input_dim=X_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=6, activation='relu', input_shape=input_dim))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(filters=16, kernel_size=2, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(filters=16, kernel_size=2, activation='relu'))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "# model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the Model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(optimizer=opt,loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7020 samples, validate on 780 samples\n",
      "Epoch 1/100\n",
      "7020/7020 [==============================] - 8s 1ms/step - loss: 0.5451 - accuracy: 0.7484 - val_loss: 0.7466 - val_accuracy: 0.6641\n",
      "Epoch 2/100\n",
      "7020/7020 [==============================] - 6s 859us/step - loss: 0.5011 - accuracy: 0.7632 - val_loss: 0.6595 - val_accuracy: 0.6641\n",
      "Epoch 3/100\n",
      "7020/7020 [==============================] - 6s 854us/step - loss: 0.4915 - accuracy: 0.7674 - val_loss: 0.7197 - val_accuracy: 0.6686\n",
      "Epoch 4/100\n",
      "7020/7020 [==============================] - 6s 859us/step - loss: 0.4842 - accuracy: 0.7689 - val_loss: 1.1446 - val_accuracy: 0.5782\n",
      "Epoch 5/100\n",
      "7020/7020 [==============================] - 6s 871us/step - loss: 0.4713 - accuracy: 0.7773 - val_loss: 1.2243 - val_accuracy: 0.6843\n",
      "Epoch 6/100\n",
      "7020/7020 [==============================] - 6s 865us/step - loss: 0.4570 - accuracy: 0.7863 - val_loss: 0.9525 - val_accuracy: 0.6647\n",
      "Epoch 7/100\n",
      "7020/7020 [==============================] - 6s 857us/step - loss: 0.4432 - accuracy: 0.7932 - val_loss: 0.6424 - val_accuracy: 0.7147\n",
      "Epoch 8/100\n",
      "7020/7020 [==============================] - 6s 867us/step - loss: 0.4223 - accuracy: 0.8055 - val_loss: 0.7142 - val_accuracy: 0.6843\n",
      "Epoch 9/100\n",
      "7020/7020 [==============================] - 6s 882us/step - loss: 0.3987 - accuracy: 0.8183 - val_loss: 0.5713 - val_accuracy: 0.7519\n",
      "Epoch 10/100\n",
      "7020/7020 [==============================] - 6s 881us/step - loss: 0.3730 - accuracy: 0.8312 - val_loss: 0.6985 - val_accuracy: 0.6798\n",
      "Epoch 11/100\n",
      "7020/7020 [==============================] - 6s 870us/step - loss: 0.3448 - accuracy: 0.8443 - val_loss: 0.9356 - val_accuracy: 0.6548\n",
      "Epoch 12/100\n",
      "7020/7020 [==============================] - 6s 869us/step - loss: 0.3138 - accuracy: 0.8620 - val_loss: 0.7892 - val_accuracy: 0.6785\n",
      "Epoch 13/100\n",
      "7020/7020 [==============================] - 6s 860us/step - loss: 0.2904 - accuracy: 0.8754 - val_loss: 1.8085 - val_accuracy: 0.6404\n",
      "Epoch 14/100\n",
      "7020/7020 [==============================] - 6s 858us/step - loss: 0.2466 - accuracy: 0.8940 - val_loss: 1.5451 - val_accuracy: 0.6942\n",
      "Epoch 15/100\n",
      "7020/7020 [==============================] - 6s 867us/step - loss: 0.2069 - accuracy: 0.9149 - val_loss: 4.1561 - val_accuracy: 0.6917\n",
      "Epoch 16/100\n",
      "7020/7020 [==============================] - 6s 849us/step - loss: 0.1904 - accuracy: 0.9209 - val_loss: 1.7646 - val_accuracy: 0.6872\n",
      "Epoch 17/100\n",
      "7020/7020 [==============================] - 6s 864us/step - loss: 0.1638 - accuracy: 0.9338 - val_loss: 3.6466 - val_accuracy: 0.6208\n",
      "Epoch 18/100\n",
      "7020/7020 [==============================] - 6s 864us/step - loss: 0.1459 - accuracy: 0.9423 - val_loss: 1.9335 - val_accuracy: 0.6974\n",
      "Epoch 19/100\n",
      "7020/7020 [==============================] - 6s 907us/step - loss: 0.1222 - accuracy: 0.9539 - val_loss: 1.4654 - val_accuracy: 0.6849\n",
      "Epoch 20/100\n",
      "7020/7020 [==============================] - 7s 930us/step - loss: 0.1011 - accuracy: 0.9628 - val_loss: 3.2093 - val_accuracy: 0.6356\n",
      "Epoch 21/100\n",
      "7020/7020 [==============================] - 6s 856us/step - loss: 0.0850 - accuracy: 0.9700 - val_loss: 1.0932 - val_accuracy: 0.7282\n",
      "Epoch 22/100\n",
      "7020/7020 [==============================] - 6s 856us/step - loss: 0.0693 - accuracy: 0.9749 - val_loss: 2.1389 - val_accuracy: 0.6660\n",
      "Epoch 23/100\n",
      "7020/7020 [==============================] - 6s 859us/step - loss: 0.0677 - accuracy: 0.9756 - val_loss: 1.6544 - val_accuracy: 0.6596\n",
      "Epoch 24/100\n",
      "7020/7020 [==============================] - 6s 861us/step - loss: 0.0541 - accuracy: 0.9808 - val_loss: 1.2911 - val_accuracy: 0.6715\n",
      "Epoch 25/100\n",
      "7020/7020 [==============================] - 6s 866us/step - loss: 0.0532 - accuracy: 0.9810 - val_loss: 1.2172 - val_accuracy: 0.7045\n",
      "Epoch 26/100\n",
      "7020/7020 [==============================] - 6s 854us/step - loss: 0.0502 - accuracy: 0.9822 - val_loss: 0.8145 - val_accuracy: 0.7051\n",
      "Epoch 27/100\n",
      "7020/7020 [==============================] - 6s 860us/step - loss: 0.0424 - accuracy: 0.9851 - val_loss: 3.0895 - val_accuracy: 0.6724\n",
      "Epoch 28/100\n",
      "7020/7020 [==============================] - 6s 862us/step - loss: 0.0450 - accuracy: 0.9849 - val_loss: 2.3943 - val_accuracy: 0.6859\n",
      "Epoch 29/100\n",
      "7020/7020 [==============================] - 6s 854us/step - loss: 0.0398 - accuracy: 0.9864 - val_loss: 5.2795 - val_accuracy: 0.6103\n",
      "Epoch 30/100\n",
      "7020/7020 [==============================] - 6s 857us/step - loss: 0.0413 - accuracy: 0.9854 - val_loss: 1.4696 - val_accuracy: 0.6990\n",
      "Epoch 31/100\n",
      "7020/7020 [==============================] - 6s 861us/step - loss: 0.0340 - accuracy: 0.9877 - val_loss: 2.5544 - val_accuracy: 0.6638\n",
      "Epoch 32/100\n",
      "7020/7020 [==============================] - 6s 864us/step - loss: 0.0286 - accuracy: 0.9904 - val_loss: 1.3493 - val_accuracy: 0.7244\n",
      "Epoch 33/100\n",
      "7020/7020 [==============================] - 6s 862us/step - loss: 0.0324 - accuracy: 0.9885 - val_loss: 3.9044 - val_accuracy: 0.6635\n",
      "Epoch 34/100\n",
      "7020/7020 [==============================] - 6s 859us/step - loss: 0.0230 - accuracy: 0.9928 - val_loss: 1.2319 - val_accuracy: 0.7240\n",
      "Epoch 35/100\n",
      "7020/7020 [==============================] - 6s 861us/step - loss: 0.0277 - accuracy: 0.9908 - val_loss: 2.4871 - val_accuracy: 0.6609\n",
      "Epoch 36/100\n",
      "7020/7020 [==============================] - 6s 857us/step - loss: 0.0457 - accuracy: 0.9843 - val_loss: 0.9459 - val_accuracy: 0.6663\n",
      "Epoch 37/100\n",
      "7020/7020 [==============================] - 6s 861us/step - loss: 0.0300 - accuracy: 0.9900 - val_loss: 2.1215 - val_accuracy: 0.6660\n",
      "Epoch 38/100\n",
      "7020/7020 [==============================] - 6s 860us/step - loss: 0.0217 - accuracy: 0.9927 - val_loss: 1.2679 - val_accuracy: 0.7282\n",
      "Epoch 39/100\n",
      "7020/7020 [==============================] - 6s 851us/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 1.4316 - val_accuracy: 0.7202\n",
      "Epoch 40/100\n",
      "7020/7020 [==============================] - 6s 859us/step - loss: 0.0200 - accuracy: 0.9936 - val_loss: 1.5969 - val_accuracy: 0.7173\n",
      "Epoch 41/100\n",
      "7020/7020 [==============================] - 6s 866us/step - loss: 0.0217 - accuracy: 0.9929 - val_loss: 1.1989 - val_accuracy: 0.7147\n",
      "Epoch 42/100\n",
      "7020/7020 [==============================] - 6s 855us/step - loss: 0.0305 - accuracy: 0.9891 - val_loss: 1.3583 - val_accuracy: 0.6929\n",
      "Epoch 43/100\n",
      "7020/7020 [==============================] - 6s 856us/step - loss: 0.0265 - accuracy: 0.9904 - val_loss: 1.1191 - val_accuracy: 0.6952\n",
      "Epoch 44/100\n",
      "7020/7020 [==============================] - 6s 857us/step - loss: 0.0425 - accuracy: 0.9834 - val_loss: 1.4906 - val_accuracy: 0.6612\n",
      "Epoch 45/100\n",
      "7020/7020 [==============================] - 6s 863us/step - loss: 0.0368 - accuracy: 0.9865 - val_loss: 1.3771 - val_accuracy: 0.7244\n",
      "Epoch 46/100\n",
      "7020/7020 [==============================] - 6s 855us/step - loss: 0.0254 - accuracy: 0.9910 - val_loss: 1.4636 - val_accuracy: 0.7192\n",
      "Epoch 47/100\n",
      "7020/7020 [==============================] - 6s 860us/step - loss: 0.0152 - accuracy: 0.9946 - val_loss: 1.5363 - val_accuracy: 0.7103\n",
      "Epoch 48/100\n",
      "7020/7020 [==============================] - 6s 853us/step - loss: 0.0132 - accuracy: 0.9953 - val_loss: 1.4350 - val_accuracy: 0.7205\n",
      "Epoch 49/100\n",
      "7020/7020 [==============================] - 6s 850us/step - loss: 0.0116 - accuracy: 0.9959 - val_loss: 1.1858 - val_accuracy: 0.7173\n",
      "Epoch 50/100\n",
      "7020/7020 [==============================] - 6s 858us/step - loss: 0.0128 - accuracy: 0.9963 - val_loss: 1.2938 - val_accuracy: 0.7375\n",
      "Epoch 51/100\n",
      "7020/7020 [==============================] - 6s 864us/step - loss: 0.0188 - accuracy: 0.9929 - val_loss: 1.3554 - val_accuracy: 0.7103\n",
      "Epoch 52/100\n",
      "7020/7020 [==============================] - 6s 855us/step - loss: 0.0163 - accuracy: 0.9941 - val_loss: 2.9759 - val_accuracy: 0.6888\n",
      "Epoch 53/100\n",
      "7020/7020 [==============================] - 6s 850us/step - loss: 0.0303 - accuracy: 0.9894 - val_loss: 2.1604 - val_accuracy: 0.6506\n",
      "Epoch 54/100\n",
      "7020/7020 [==============================] - 6s 850us/step - loss: 0.0229 - accuracy: 0.9923 - val_loss: 1.7027 - val_accuracy: 0.6814\n",
      "Epoch 55/100\n",
      "7020/7020 [==============================] - 6s 854us/step - loss: 0.0200 - accuracy: 0.9927 - val_loss: 1.2330 - val_accuracy: 0.7067\n",
      "Epoch 56/100\n",
      "7020/7020 [==============================] - 6s 857us/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 1.7938 - val_accuracy: 0.7202\n",
      "Epoch 57/100\n",
      "7020/7020 [==============================] - 6s 855us/step - loss: 0.0173 - accuracy: 0.9930 - val_loss: 1.4251 - val_accuracy: 0.7308\n",
      "Epoch 58/100\n",
      "7020/7020 [==============================] - 6s 856us/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 2.0682 - val_accuracy: 0.7144\n",
      "Epoch 59/100\n",
      "7020/7020 [==============================] - 6s 860us/step - loss: 0.0161 - accuracy: 0.9941 - val_loss: 1.3676 - val_accuracy: 0.6599\n",
      "Epoch 60/100\n",
      "7020/7020 [==============================] - 6s 870us/step - loss: 0.0144 - accuracy: 0.9955 - val_loss: 1.3566 - val_accuracy: 0.6888\n",
      "Epoch 61/100\n",
      "7020/7020 [==============================] - 6s 888us/step - loss: 0.0187 - accuracy: 0.9932 - val_loss: 1.7474 - val_accuracy: 0.7058\n",
      "Epoch 62/100\n",
      "7020/7020 [==============================] - 6s 879us/step - loss: 0.0241 - accuracy: 0.9915 - val_loss: 1.6088 - val_accuracy: 0.7282\n",
      "Epoch 63/100\n",
      "7020/7020 [==============================] - 6s 857us/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 1.4982 - val_accuracy: 0.7228\n",
      "Epoch 64/100\n",
      "7020/7020 [==============================] - 6s 857us/step - loss: 0.0148 - accuracy: 0.9948 - val_loss: 1.6890 - val_accuracy: 0.7170\n",
      "Epoch 65/100\n",
      "7020/7020 [==============================] - 6s 857us/step - loss: 0.0137 - accuracy: 0.9950 - val_loss: 1.6548 - val_accuracy: 0.7250\n",
      "Epoch 66/100\n",
      "7020/7020 [==============================] - 6s 855us/step - loss: 0.0144 - accuracy: 0.9945 - val_loss: 1.6698 - val_accuracy: 0.7279\n",
      "Epoch 67/100\n",
      "7020/7020 [==============================] - 6s 854us/step - loss: 0.0171 - accuracy: 0.9939 - val_loss: 1.6662 - val_accuracy: 0.7035\n",
      "Epoch 68/100\n",
      "7020/7020 [==============================] - 6s 857us/step - loss: 0.0173 - accuracy: 0.9942 - val_loss: 1.6338 - val_accuracy: 0.7083\n",
      "Epoch 69/100\n",
      "7020/7020 [==============================] - 6s 851us/step - loss: 0.0142 - accuracy: 0.9946 - val_loss: 1.1259 - val_accuracy: 0.6990\n",
      "Epoch 70/100\n",
      "7020/7020 [==============================] - 7s 934us/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 1.7356 - val_accuracy: 0.6891\n",
      "Epoch 71/100\n",
      "7020/7020 [==============================] - 6s 855us/step - loss: 0.0181 - accuracy: 0.9945 - val_loss: 1.5319 - val_accuracy: 0.7199\n",
      "Epoch 72/100\n",
      "7020/7020 [==============================] - 6s 858us/step - loss: 0.0181 - accuracy: 0.9942 - val_loss: 1.5314 - val_accuracy: 0.7237\n",
      "Epoch 73/100\n",
      "7020/7020 [==============================] - 6s 859us/step - loss: 0.0152 - accuracy: 0.9942 - val_loss: 1.9343 - val_accuracy: 0.6683\n",
      "Epoch 74/100\n",
      "7020/7020 [==============================] - 6s 853us/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 1.6022 - val_accuracy: 0.7163\n",
      "Epoch 75/100\n",
      "7020/7020 [==============================] - 6s 860us/step - loss: 0.0103 - accuracy: 0.9962 - val_loss: 1.4726 - val_accuracy: 0.7292\n",
      "Epoch 76/100\n",
      "7020/7020 [==============================] - 6s 853us/step - loss: 0.0146 - accuracy: 0.9952 - val_loss: 1.1407 - val_accuracy: 0.6933\n",
      "Epoch 77/100\n",
      "7020/7020 [==============================] - 6s 863us/step - loss: 0.0079 - accuracy: 0.9972 - val_loss: 1.5303 - val_accuracy: 0.7221\n",
      "Epoch 78/100\n",
      "7020/7020 [==============================] - 6s 861us/step - loss: 0.0110 - accuracy: 0.9960 - val_loss: 1.5367 - val_accuracy: 0.7324\n",
      "Epoch 79/100\n",
      "7020/7020 [==============================] - 6s 851us/step - loss: 0.0204 - accuracy: 0.9927 - val_loss: 2.0237 - val_accuracy: 0.7112\n",
      "Epoch 80/100\n",
      "7020/7020 [==============================] - 6s 854us/step - loss: 0.0156 - accuracy: 0.9950 - val_loss: 1.5582 - val_accuracy: 0.7301\n",
      "Epoch 81/100\n",
      "7020/7020 [==============================] - 6s 853us/step - loss: 0.0104 - accuracy: 0.9967 - val_loss: 1.3066 - val_accuracy: 0.6792\n",
      "Epoch 82/100\n",
      "7020/7020 [==============================] - 6s 860us/step - loss: 0.0134 - accuracy: 0.9952 - val_loss: 1.6079 - val_accuracy: 0.7183\n",
      "Epoch 83/100\n",
      "7020/7020 [==============================] - 6s 851us/step - loss: 0.0102 - accuracy: 0.9962 - val_loss: 1.4650 - val_accuracy: 0.7253\n",
      "Epoch 84/100\n",
      "7020/7020 [==============================] - 6s 854us/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 1.3052 - val_accuracy: 0.6804\n",
      "Epoch 85/100\n",
      "7020/7020 [==============================] - 6s 864us/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 1.6949 - val_accuracy: 0.7093\n",
      "Epoch 86/100\n",
      "7020/7020 [==============================] - 6s 858us/step - loss: 0.0070 - accuracy: 0.9984 - val_loss: 1.5244 - val_accuracy: 0.6968\n",
      "Epoch 87/100\n",
      "7020/7020 [==============================] - 6s 857us/step - loss: 0.0084 - accuracy: 0.9967 - val_loss: 1.0521 - val_accuracy: 0.7054\n",
      "Epoch 88/100\n",
      "7020/7020 [==============================] - 6s 866us/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 1.7437 - val_accuracy: 0.7074\n",
      "Epoch 89/100\n",
      "7020/7020 [==============================] - 6s 850us/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 1.7609 - val_accuracy: 0.7298\n",
      "Epoch 90/100\n",
      "7020/7020 [==============================] - 6s 861us/step - loss: 0.0152 - accuracy: 0.9948 - val_loss: 2.0703 - val_accuracy: 0.7115\n",
      "Epoch 91/100\n",
      "7020/7020 [==============================] - 6s 859us/step - loss: 0.0186 - accuracy: 0.9932 - val_loss: 1.4953 - val_accuracy: 0.6792\n",
      "Epoch 92/100\n",
      "7020/7020 [==============================] - 6s 864us/step - loss: 0.0156 - accuracy: 0.9939 - val_loss: 1.8123 - val_accuracy: 0.7042\n",
      "Epoch 93/100\n",
      "7020/7020 [==============================] - 6s 861us/step - loss: 0.0120 - accuracy: 0.9965 - val_loss: 1.4440 - val_accuracy: 0.7304\n",
      "Epoch 94/100\n",
      "7020/7020 [==============================] - 6s 852us/step - loss: 0.0113 - accuracy: 0.9962 - val_loss: 1.4251 - val_accuracy: 0.7103\n",
      "Epoch 95/100\n",
      "7020/7020 [==============================] - 6s 858us/step - loss: 0.0140 - accuracy: 0.9948 - val_loss: 1.9151 - val_accuracy: 0.6901\n",
      "Epoch 96/100\n",
      "7020/7020 [==============================] - 6s 855us/step - loss: 0.0161 - accuracy: 0.9949 - val_loss: 1.7414 - val_accuracy: 0.7260\n",
      "Epoch 97/100\n",
      "7020/7020 [==============================] - 6s 861us/step - loss: 0.0091 - accuracy: 0.9967 - val_loss: 1.6067 - val_accuracy: 0.7266\n",
      "Epoch 98/100\n",
      "7020/7020 [==============================] - 6s 854us/step - loss: 0.0086 - accuracy: 0.9971 - val_loss: 1.7095 - val_accuracy: 0.6984\n",
      "Epoch 99/100\n",
      "7020/7020 [==============================] - 6s 852us/step - loss: 0.0068 - accuracy: 0.9979 - val_loss: 1.7232 - val_accuracy: 0.7099\n",
      "Epoch 100/100\n",
      "7020/7020 [==============================] - 6s 859us/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 2.0165 - val_accuracy: 0.7109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f78ca3ec208>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100,verbose=1,validation_data=(X_test, y_test))  # train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = model.evaluate(X_test, y_test)  # evaluate the out of sample data with model\n",
    "print(\"Loss:\",val_loss)  # model's loss (error)\n",
    "print(\"Accuracy:\",val_acc*100)  # model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=6, activation='relu', input_shape=input_dim))\n",
    "model.add(Conv1D(filters=16, kernel_size=3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10, verbose=0)\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
